{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read data...\n"
     ]
    }
   ],
   "source": [
    "print('Read data...')\n",
    "## read data\n",
    "path = 'G:/다른 컴퓨터/My_desktop/project/study/kaggle/data/dynamic new york'\n",
    "train = pd.read_csv(path + '/train.csv')\n",
    "test = pd.read_csv(path + '/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dates\n",
    "train['pickup_datetime'] = pd.to_datetime(train['pickup_datetime'])\n",
    "test['pickup_datetime'] = pd.to_datetime(test['pickup_datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## transform character to numeric\n",
    "le = LabelEncoder()\n",
    "le.fit(train['store_and_fwd_flag'])\n",
    "train['store_and_fwd_flag'] = le.transform(train['store_and_fwd_flag'])\n",
    "test['store_and_fwd_flag'] = le.transform(test['store_and_fwd_flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create features...\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "## New features\n",
    "###############################################################################\n",
    "print('Create features...')\n",
    "#### date features\n",
    "train['month'] = train['pickup_datetime'].dt.month\n",
    "train['day'] = train['pickup_datetime'].dt.day\n",
    "train['weekday'] = train['pickup_datetime'].dt.weekday\n",
    "train['hour'] = train['pickup_datetime'].dt.hour\n",
    "train['minute'] = train['pickup_datetime'].dt.minute\n",
    "\n",
    "test['month'] = test['pickup_datetime'].dt.month\n",
    "test['day'] = test['pickup_datetime'].dt.day\n",
    "test['weekday'] = test['pickup_datetime'].dt.weekday\n",
    "test['hour'] = test['pickup_datetime'].dt.hour\n",
    "test['minute'] = test['pickup_datetime'].dt.minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### distance features\n",
    "train['dist_long'] = train['pickup_longitude'] - train['dropoff_longitude']\n",
    "test['dist_long'] = test['pickup_longitude'] - test['dropoff_longitude']\n",
    "\n",
    "train['dist_lat'] = train['pickup_latitude'] - train['dropoff_latitude']\n",
    "test['dist_lat'] = test['pickup_latitude'] - test['dropoff_latitude']\n",
    "\n",
    "train['dist'] = np.sqrt(np.square(train['dist_long']) + np.square(train['dist_lat']))\n",
    "test['dist'] = np.sqrt(np.square(test['dist_long']) + np.square(test['dist_lat']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### spatial features: count and speed\n",
    "train['pickup_longitude_bin'] = np.round(train['pickup_longitude'], 2)\n",
    "train['pickup_latitude_bin'] = np.round(train['pickup_latitude'], 2)\n",
    "train['dropoff_longitude_bin'] = np.round(train['dropoff_longitude'], 2)\n",
    "train['dropoff_latitude_bin'] = np.round(train['dropoff_latitude'], 2)\n",
    "\n",
    "test['pickup_longitude_bin'] = np.round(test['pickup_longitude'], 2)\n",
    "test['pickup_latitude_bin'] = np.round(test['pickup_latitude'], 2)\n",
    "test['dropoff_longitude_bin'] = np.round(test['dropoff_longitude'], 2)\n",
    "test['dropoff_latitude_bin'] = np.round(test['dropoff_latitude'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## count features\n",
    "a = pd.concat([train,test]).groupby(['pickup_longitude_bin', 'pickup_latitude_bin']).size().reset_index()\n",
    "b = pd.concat([train,test]).groupby(['dropoff_longitude_bin', 'dropoff_latitude_bin']).size().reset_index()\n",
    "\n",
    "train = pd.merge(train, a, on = ['pickup_longitude_bin', 'pickup_latitude_bin'], how = 'left')\n",
    "test = pd.merge(test, a, on = ['pickup_longitude_bin', 'pickup_latitude_bin'], how = 'left')\n",
    "\n",
    "train = pd.merge(train, b, on = ['dropoff_longitude_bin', 'dropoff_latitude_bin'], how = 'left')\n",
    "test = pd.merge(test, b, on = ['dropoff_longitude_bin', 'dropoff_latitude_bin'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## speed features\n",
    "train['speed'] = 100000*train['dist'] / train['trip_duration']\n",
    "\n",
    "a = train[['speed', 'pickup_longitude_bin', 'pickup_latitude_bin']].groupby(['pickup_longitude_bin', 'pickup_latitude_bin']).mean().reset_index()\n",
    "a = a.rename(columns = {'speed': 'ave_speed'})\n",
    "b = train[['speed', 'dropoff_longitude_bin', 'dropoff_latitude_bin']].groupby(['dropoff_longitude_bin', 'dropoff_latitude_bin']).mean().reset_index()\n",
    "b = b.rename(columns = {'speed': 'ave_speed'})\n",
    "\n",
    "train = pd.merge(train, a, on = ['pickup_longitude_bin', 'pickup_latitude_bin'], how = 'left')\n",
    "test = pd.merge(test, a, on = ['pickup_longitude_bin', 'pickup_latitude_bin'], how = 'left')\n",
    "\n",
    "train = pd.merge(train, b, on = ['dropoff_longitude_bin', 'dropoff_latitude_bin'], how = 'left')\n",
    "test = pd.merge(test, b, on = ['dropoff_longitude_bin', 'dropoff_latitude_bin'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop bins\n",
    "train = train.drop(['speed', 'pickup_longitude_bin', 'pickup_latitude_bin', 'dropoff_longitude_bin', 'dropoff_latitude_bin'], axis = 1)\n",
    "test = test.drop(['pickup_longitude_bin', 'pickup_latitude_bin', 'dropoff_longitude_bin', 'dropoff_latitude_bin'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### weather data\n",
    "weather = pd.read_csv(path + '/KNYC_Metars.csv')\n",
    "weather['Time'] = pd.to_datetime(weather['Time'])\n",
    "weather['year'] = weather['Time'].dt.year\n",
    "weather['month'] = weather['Time'].dt.month\n",
    "weather['day'] = weather['Time'].dt.day\n",
    "weather['hour'] = weather['Time'].dt.hour\n",
    "weather = weather[weather['year'] == 2016]\n",
    "\n",
    "train = pd.merge(train, weather[['Temp.', 'month', 'day', 'hour']], on = ['month', 'day', 'hour'], how = 'left')\n",
    "test = pd.merge(test, weather[['Temp.', 'month', 'day', 'hour']], on = ['month', 'day', 'hour'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train/test features, y, id\n",
    "xtrain = train.drop(['id', 'pickup_datetime', 'dropoff_datetime', 'trip_duration'], axis=1).values\n",
    "xtest = test.drop(['id', 'pickup_datetime'], axis=1).values\n",
    "\n",
    "ytrain = train['trip_duration'].values\n",
    "id_train = train['id'].values\n",
    "id_test = test['id'].values\n",
    "del(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model...\n"
     ]
    }
   ],
   "source": [
    "## xgb parameters\n",
    "params = {\n",
    "    'booster':            'gbtree',\n",
    "    # 'objective':          'reg:linear',\n",
    "    'objective': 'reg:squarederror',\n",
    "    'learning_rate':      0.1,\n",
    "    'max_depth':          14,\n",
    "    'subsample':          0.8,\n",
    "    'colsample_bytree':   0.7,\n",
    "    'colsample_bylevel':  0.7,\n",
    "    # 'silent':             1\n",
    "    'verbosity': 1\n",
    "}\n",
    "\n",
    "## number of rounds\n",
    "nrounds = 200\n",
    "\n",
    "## train model\n",
    "print('Train model...')\n",
    "dtrain = xgb.DMatrix(xtrain, np.log(ytrain+1))\n",
    "gbm = xgb.train(params,\n",
    "                dtrain,\n",
    "                num_boost_round = nrounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test predictions\n",
    "pred_test = np.exp(gbm.predict(xgb.DMatrix(xtest))) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create submission\n",
    "df = pd.DataFrame({'id': id_test, 'trip_duration': pred_test}) \n",
    "df = df.set_index('id')\n",
    "df.to_csv('sub_bench.csv', index = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
